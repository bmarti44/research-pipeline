2026-02-14 06:26:24.414686: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2026-02-14 06:26:24.427048: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1771050384.441831   20266 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1771050384.446481   20266 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1771050384.458044   20266 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1771050384.458065   20266 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1771050384.458067   20266 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1771050384.458068   20266 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2026-02-14 06:26:24.461238: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI, in other operations, rebuild TensorFlow with the appropriate compiler flags.
Loaded 500 samples
Bonferroni threshold: 0.000641

============================================================
Model: m5
============================================================
  Extracting hidden states (GPU)...
The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
[load_model] Resized embeddings: 50260 -> 50260
[load_model] Coconut (pause_curriculum) loaded from /lambda/nfs/experiment/results/v9_meta_fork/prosqa-m5-pause/checkpoint_50
  Missing keys: []
  Unexpected keys: []
    100/500
    200/500
    300/500
    400/500
    500/500
  Extraction done in 6.1s
  Saved hidden states to /lambda/nfs/experiment/results/v9_meta_fork/experiments/probing_corrected/m5_hidden_states.npz
  Running linear probes + permutation tests...
    Position 0: n=500, 38 classes
      L0: acc=0.0320, p=0.246377 (43.3s)
      L1: acc=0.0360, p=0.277861 (44.2s)
      L2: acc=0.0580, p=0.053473 (46.2s)
      L3: acc=0.0500, p=0.128936 (44.8s)
      L4: acc=0.0520, p=0.055472 (44.2s)
      L5: acc=0.0680, p=0.019490 (45.6s)
      L6: acc=0.0740, p=0.004498 (46.6s)
      L7: acc=0.1040, p=0.000500 (45.7s) ***
      L8: acc=0.2360, p=0.000500 (42.2s) ***
      L9: acc=0.1460, p=0.000500 (42.4s) ***
      L10: acc=0.1100, p=0.000500 (45.3s) ***
      L11: acc=0.1000, p=0.001000 (44.9s)
      L12: acc=0.1020, p=0.000500 (49.0s) ***
    -> Peak: layer 8, acc=0.2360, p=0.000500, sig=5/13
    Position 1: n=500, 38 classes
      L0: acc=0.0320, p=0.276362 (45.6s)
      L1: acc=0.0180, p=0.733133 (47.5s)
      L2: acc=0.0300, p=0.260370 (50.1s)
      L3: acc=0.0300, p=0.484758 (47.8s)
      L4: acc=0.0360, p=0.254373 (47.4s)
      L5: acc=0.0300, p=0.276362 (46.5s)
      L6: acc=0.0580, p=0.045977 (47.4s)
      L7: acc=0.0400, p=0.258371 (46.7s)
      L8: acc=0.0540, p=0.052474 (47.5s)
      L9: acc=0.0920, p=0.000500 (46.7s) ***
      L10: acc=0.0900, p=0.001000 (44.6s)
      L11: acc=0.1040, p=0.000500 (44.6s) ***
      L12: acc=0.0780, p=0.002999 (44.7s)
    -> Peak: layer 11, acc=0.1040, p=0.000500, sig=2/13
    Position 2: n=500, 38 classes
      L0: acc=0.0440, p=0.115442 (45.1s)
      L1: acc=0.0500, p=0.114943 (47.0s)
      L2: acc=0.0440, p=0.113943 (48.5s)
      L3: acc=0.0420, p=0.125437 (46.2s)
      L4: acc=0.0440, p=0.131934 (46.2s)
      L5: acc=0.0580, p=0.054973 (47.6s)
      L6: acc=0.0460, p=0.115942 (44.2s)
      L7: acc=0.0340, p=0.269365 (44.3s)
      L8: acc=0.0380, p=0.260870 (45.9s)
      L9: acc=0.0680, p=0.013993 (44.0s)
      L10: acc=0.0660, p=0.016492 (44.9s)
      L11: acc=0.2160, p=0.000500 (42.3s) ***
      L12: acc=0.2200, p=0.000500 (44.2s) ***
    -> Peak: layer 12, acc=0.2200, p=0.000500, sig=2/13
    Position 3: n=298, 38 classes
      L0: acc=0.0436, p=0.197901 (45.2s)
      L1: acc=0.0638, p=0.053973 (44.5s)
      L2: acc=0.0503, p=0.059470 (43.5s)
      L3: acc=0.0738, p=0.020990 (44.8s)
      L4: acc=0.0839, p=0.002999 (42.4s)
      L5: acc=0.1141, p=0.001000 (40.5s)
      L6: acc=0.0839, p=0.003998 (41.7s)
      L7: acc=0.0470, p=0.210395 (44.0s)
      L8: acc=0.0268, p=0.458271 (43.7s)
      L9: acc=0.0302, p=0.469265 (45.3s)
      L10: acc=0.0470, p=0.181409 (39.9s)
      L11: acc=0.5302, p=0.000500 (41.3s) ***
      L12: acc=0.5705, p=0.000500 (41.4s) ***
    -> Peak: layer 12, acc=0.5705, p=0.000500, sig=2/13
    Position 4: n=81, 32 classes
      L0: acc=0.0000, p=1.000000 (0.0s)
      L1: acc=0.0000, p=1.000000 (0.0s)
      L2: acc=0.0000, p=1.000000 (0.0s)
      L3: acc=0.0000, p=1.000000 (0.0s)
      L4: acc=0.0000, p=1.000000 (0.0s)
      L5: acc=0.0000, p=1.000000 (0.0s)
      L6: acc=0.0000, p=1.000000 (0.0s)
      L7: acc=0.0000, p=1.000000 (0.0s)
      L8: acc=0.0000, p=1.000000 (0.0s)
      L9: acc=0.0000, p=1.000000 (0.0s)
      L10: acc=0.0000, p=1.000000 (0.0s)
      L11: acc=0.0000, p=1.000000 (0.0s)
      L12: acc=0.0000, p=1.000000 (0.0s)
    -> Peak: layer 0, acc=0.0000, p=1.000000, sig=0/13
    Position 5: n=12, 12 classes
      L0: acc=0.0000, p=1.000000 (0.0s)
      L1: acc=0.0000, p=1.000000 (0.0s)
      L2: acc=0.0000, p=1.000000 (0.0s)
      L3: acc=0.0000, p=1.000000 (0.0s)
      L4: acc=0.0000, p=1.000000 (0.0s)
      L5: acc=0.0000, p=1.000000 (0.0s)
      L6: acc=0.0000, p=1.000000 (0.0s)
      L7: acc=0.0000, p=1.000000 (0.0s)
      L8: acc=0.0000, p=1.000000 (0.0s)
      L9: acc=0.0000, p=1.000000 (0.0s)
      L10: acc=0.0000, p=1.000000 (0.0s)
      L11: acc=0.0000, p=1.000000 (0.0s)
      L12: acc=0.0000, p=1.000000 (0.0s)
    -> Peak: layer 0, acc=0.0000, p=1.000000, sig=0/13
  All probes done in 2340.2s (39.0 min)
  Saved m5 results to /lambda/nfs/experiment/results/v9_meta_fork/experiments/probing_corrected/m5_linear_perm.json

======================================================================
CORRECTED LINEAR PROBE + PERMUTATION RESULTS
======================================================================

m5:
  Peak linear: layer 12, pos 3, acc=0.5705
  Significant cells (Bonferroni): 11/78
  Significant cell locations:
    layer=7, pos=0: acc=0.1040, p=0.000500
    layer=8, pos=0: acc=0.2360, p=0.000500
    layer=9, pos=0: acc=0.1460, p=0.000500
    layer=9, pos=1: acc=0.0920, p=0.000500
    layer=10, pos=0: acc=0.1100, p=0.000500
    layer=11, pos=1: acc=0.1040, p=0.000500
    layer=11, pos=2: acc=0.2160, p=0.000500
    layer=11, pos=3: acc=0.5302, p=0.000500
    layer=12, pos=0: acc=0.1020, p=0.000500
    layer=12, pos=2: acc=0.2200, p=0.000500
    layer=12, pos=3: acc=0.5705, p=0.000500

Done.
