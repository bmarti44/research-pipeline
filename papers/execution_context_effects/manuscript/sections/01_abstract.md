# Abstract

We investigated whether requiring structured JSON tool calls causes failures that wouldn't occur with natural language output. In Study 1 (n=80 trials), we found that JSON serialization failures are rare (< 2%)—models produce syntactically valid JSON 100% of the time. However, we observed significant performance differences between conditions (NL: 97.5% vs JSON: 70.0%, p < 0.001). In Study 2 (n=80 trials), we investigated these behavioral differences and found that execution context triggers operation-specific caution: when output will actually execute (JSON mode), models adopt safer behaviors for destructive operations, particularly "read before edit" patterns. This effect is operation-specific (100% for edit operations, 0% for create operations) rather than complexity-driven. The performance gap persisted (NL: 90.0% vs JSON: 72.5%, p = 0.045). We argue that observed "format friction" is better understood as alignment activation—the model being appropriately cautious when its output has real consequences. This reframes what appears to be a capability limitation as potentially desirable safety behavior.

**Keywords:** large language models, tool use, structured output, alignment, agentic systems
