# M6: Pause-Multipass (single GPU)
# Confound-resolving control: same 6-pass sequential KV-cache processing as M3,
# but re-injects a fixed learned <pause> embedding at each step instead of
# recycled hidden states. Isolates factor (1) recycled content from factor (2)
# sequential processing structure.
# M3 vs M6: tests whether recycled content matters (matched processing structure)
# M5 vs M6: tests whether sequential processing matters (matched fixed embeddings)
project: coconut
save_path: ../results
name: prosqa-m6-pause-multipass

only_eval: False

coconut: True
cot: False
no_thoughts: False
no_cot: False
feedback_mode: pause_multipass

c_thought: 1
epochs_per_stage: 5
max_latent_stage: 6
pad_latent_to_max: True

save_only_improve: False
uniform_prob: 0.0
model_id: openai-community/gpt2
load_model_path: None
seed: 0
resume: 0
bf16: False
train_path: data/prosqa_train.json
val_path: data/prosqa_valid.json
reset_optimizer: True
batch_size_training: 32
debug: False
gradient_accumulation_steps: 4
num_epochs: 50
lr: !!float "1e-4"
weight_decay: 0.01
