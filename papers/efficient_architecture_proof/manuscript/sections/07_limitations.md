## 6. Limitations

**Scale.** All experiments use GPT-2 124M, a model with 12 layers and 768-dimensional hidden states. Zhang et al. (2025) conducted their causal intervention study on LLaMA 7B and 8B, which are 56-64 times larger. It is possible that the continuous thought mechanism provides benefits that emerge only at larger scale, where the model has sufficient capacity to learn the superposition states that Zhu et al. (2025) proved are theoretically available. Our negative results establish that the mechanism is not necessary for ProsQA performance at 124M parameters, but they do not rule out scale-dependent effects. Replication at LLaMA-class scale would substantially strengthen or weaken our claims.

**Task complexity.** ProsQA is a synthetic graph-traversal benchmark with perfectly structured, unambiguous reasoning paths. Each problem has a unique correct answer, the graph topology is fully specified, and there is no lexical or semantic ambiguity. Natural language reasoning involves noise, underspecification, conflicting evidence, and graded plausibility. The recycling mechanism's ability to encode superposition states (Zhu et al., 2025) may be more valuable in settings where the model must maintain multiple candidate interpretations simultaneously -- a capacity that ProsQA's deterministic structure does not require. Our conclusions are specific to tasks with this structural profile and should not be generalized without further testing.

**Single seed.** All results are from a single training seed (seed 0). The 2.4-percentage-point test-set gap between M3 (98.0%) and M5 (95.6%) could narrow, widen, or reverse under different random initializations. The out-of-distribution advantages we report for M5 -- including the 9.4-point gap on 7-hop paths -- may similarly reflect seed-specific training dynamics rather than systematic architectural differences. Multi-seed replication with proper paired statistical tests would provide confidence intervals around these estimates and clarify which differences are robust to initialization variance.

**Probing measures presence, not use.** M3's 10.5% mean thought-position advantage over input positions demonstrates that the recycling mechanism has a measurable effect on the model's internal representations. The mechanism is not "doing nothing" -- it injects decodable information that the pause baseline does not contain. Our claim is narrower: this information is not functionally used by the model's downstream computation, as evidenced by zero selectivity scores and comparable task accuracy. But the distinction between presence and use is subtle. A more sensitive behavioral measure, or a different probing methodology, might reveal functional consequences of the representational difference that our current analysis misses.

**Approximate McNemar tests.** Our McNemar tests are computed from aggregate accuracy figures (percentage correct out of 500 samples) rather than from per-sample paired response data. This approximation treats all samples within a condition as exchangeable and does not account for item-level difficulty variation. True paired tests, computed from per-sample agreement tables, would provide more precise p-values and could reveal significance patterns that the aggregate approximation obscures. The Bonferroni-corrected p-values we report should be interpreted with this caveat in mind.
