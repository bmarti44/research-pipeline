Meta's COCONUT replaces explicit chain-of-thought with continuous latent thought tokens, recycling transformer hidden states as input embeddings across multiple reasoning steps. On ProsQA, a synthetic graph-traversal benchmark, COCONUT achieves 97% accuracy, substantially outperforming chain-of-thought baselines. The original work attributes this gain to the continuous latent space, which is hypothesized to encode richer, parallelized reasoning than discrete token sequences. However, COCONUT's training relies on a 7-stage curriculum that progressively removes explicit reasoning tokens, a confound that has not been controlled for. We construct M5, a compute-matched pause-token baseline that receives the same GPT-2 124M architecture, the same curriculum schedule, and the same number of latent positions, but replaces the recycled hidden states with fixed learned pause embeddings that carry no information between steps. M5 reaches 95.6% test accuracy, closing 85% of the gap between chain-of-thought (83.0%) and COCONUT (98.0%). Three converging experiments fail to distinguish the two systems: token corruption produces identical degradation profiles with zero permutation sensitivity, linear probes recover comparable intermediate reasoning information (peak accuracy 55.4% for COCONUT vs. 57.1% for M5, selectivity 0.0 for both), and cross-model thought transplantation succeeds in both directions. On out-of-distribution generalization, M5 outperforms COCONUT on 3 of 4 test sets, including a 9.4 percentage-point advantage on 7-hop paths (p = 0.007, Bonferroni-corrected). These results indicate that the curriculum, not the continuous latent mechanism, drives COCONUT's in-distribution performance, and that the recycling mechanism may constrain generalization.
